{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.12.1\n",
        "!pip install torchvision==0.13.1\n",
        "!pip install rich==12.5.1\n",
        "!pip install opencv-python==4.6.0.66\n",
        "!pip install tqdm==4.64.1\n",
        "!pip install git+https://github.com/tryolabs/norfair.git@master"
      ],
      "metadata": {
        "id": "TpPT3jsXcGNJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ce93dd1-7cc4-44c8-dab1-ef50a9c7e9a0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.12.1\n",
            "  Downloading torch-1.12.1-cp310-cp310-manylinux1_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.12.1) (4.12.2)\n",
            "Downloading torch-1.12.1-cp310-cp310-manylinux1_x86_64.whl (776.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu121\n",
            "    Uninstalling torch-2.5.1+cu121:\n",
            "      Successfully uninstalled torch-2.5.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "peft 0.14.0 requires torch>=1.13.0, but you have torch 1.12.1 which is incompatible.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 1.12.1 which is incompatible.\n",
            "torchvision 0.20.1+cu121 requires torch==2.5.1, but you have torch 1.12.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.12.1\n",
            "Collecting torchvision==0.13.1\n",
            "  Downloading torchvision-0.13.1-cp310-cp310-manylinux1_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torchvision==0.13.1) (4.12.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.13.1) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.13.1) (2.32.3)\n",
            "Requirement already satisfied: torch==1.12.1 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.13.1) (1.12.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.13.1) (11.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.13.1) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.13.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.13.1) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.13.1) (2024.12.14)\n",
            "Downloading torchvision-0.13.1-cp310-cp310-manylinux1_x86_64.whl (19.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torchvision\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.1+cu121\n",
            "    Uninstalling torchvision-0.20.1+cu121:\n",
            "      Successfully uninstalled torchvision-0.20.1+cu121\n",
            "Successfully installed torchvision-0.13.1\n",
            "Collecting rich==12.5.1\n",
            "  Downloading rich-12.5.1-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting commonmark<0.10.0,>=0.9.0 (from rich==12.5.1)\n",
            "  Downloading commonmark-0.9.1-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from rich==12.5.1) (2.18.0)\n",
            "Downloading rich-12.5.1-py3-none-any.whl (235 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.6/235.6 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading commonmark-0.9.1-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: commonmark, rich\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.9.4\n",
            "    Uninstalling rich-13.9.4:\n",
            "      Successfully uninstalled rich-13.9.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pymc 5.19.1 requires rich>=13.7.1, but you have rich 12.5.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed commonmark-0.9.1 rich-12.5.1\n",
            "Collecting opencv-python==4.6.0.66\n",
            "  Downloading opencv_python-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python==4.6.0.66) (1.26.4)\n",
            "Downloading opencv_python-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: opencv-python\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.10.0.84\n",
            "    Uninstalling opencv-python-4.10.0.84:\n",
            "      Successfully uninstalled opencv-python-4.10.0.84\n",
            "Successfully installed opencv-python-4.6.0.66\n",
            "Collecting tqdm==4.64.1\n",
            "  Downloading tqdm-4.64.1-py2.py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.3/57.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tqdm\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "peft 0.14.0 requires torch>=1.13.0, but you have torch 1.12.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tqdm-4.64.1\n",
            "Collecting git+https://github.com/tryolabs/norfair.git@master\n",
            "  Cloning https://github.com/tryolabs/norfair.git (to revision master) to /tmp/pip-req-build-zd34hjjn\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/tryolabs/norfair.git /tmp/pip-req-build-zd34hjjn\n",
            "  Resolved https://github.com/tryolabs/norfair.git to commit ac9c00b917329e292a64d64bd6be32eafc849594\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting filterpy<2.0.0,>=1.4.5 (from norfair==2.2.0)\n",
            "  Downloading filterpy-1.4.5.zip (177 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.0/178.0 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.0 in /usr/local/lib/python3.10/dist-packages (from norfair==2.2.0) (1.26.4)\n",
            "Requirement already satisfied: rich<13.0.0,>=9.10.0 in /usr/local/lib/python3.10/dist-packages (from norfair==2.2.0) (12.5.1)\n",
            "Requirement already satisfied: scipy>=1.5.4 in /usr/local/lib/python3.10/dist-packages (from norfair==2.2.0) (1.13.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from filterpy<2.0.0,>=1.4.5->norfair==2.2.0) (3.10.0)\n",
            "Requirement already satisfied: commonmark<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from rich<13.0.0,>=9.10.0->norfair==2.2.0) (0.9.1)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from rich<13.0.0,>=9.10.0->norfair==2.2.0) (2.18.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy<2.0.0,>=1.4.5->norfair==2.2.0) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy<2.0.0,>=1.4.5->norfair==2.2.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy<2.0.0,>=1.4.5->norfair==2.2.0) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy<2.0.0,>=1.4.5->norfair==2.2.0) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy<2.0.0,>=1.4.5->norfair==2.2.0) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy<2.0.0,>=1.4.5->norfair==2.2.0) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy<2.0.0,>=1.4.5->norfair==2.2.0) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->filterpy<2.0.0,>=1.4.5->norfair==2.2.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->filterpy<2.0.0,>=1.4.5->norfair==2.2.0) (1.17.0)\n",
            "Building wheels for collected packages: norfair, filterpy\n",
            "  Building wheel for norfair (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for norfair: filename=norfair-2.2.0-py3-none-any.whl size=56119 sha256=b8249d3257cd88f5d3a13968d22cd12bc3e3e7c3c5f6f6b4db3b0abe1f8dd5bf\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-hoe68pfw/wheels/7d/2c/aa/72f3e88e28c4cab4026deaceb1fd228605673cf69a0905b765\n",
            "  Building wheel for filterpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for filterpy: filename=filterpy-1.4.5-py3-none-any.whl size=110458 sha256=f55d55974ad9a9b28d92e345ba0ea814645fecc71c868cbc28c17b6fef8ed873\n",
            "  Stored in directory: /root/.cache/pip/wheels/0f/0c/ea/218f266af4ad626897562199fbbcba521b8497303200186102\n",
            "Successfully built norfair filterpy\n",
            "Installing collected packages: filterpy, norfair\n",
            "Successfully installed filterpy-1.4.5 norfair-2.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import norfair\n",
        "\n",
        "def draw(\n",
        "    paths_drawer,\n",
        "    track_points,\n",
        "    frame,\n",
        "    detections,\n",
        "    tracked_objects,\n",
        "    coord_transformations,\n",
        "    fix_paths,\n",
        "):\n",
        "    if track_points == \"centroid\":\n",
        "        norfair.draw_points(frame, detections)\n",
        "        norfair.draw_tracked_objects(frame, tracked_objects)\n",
        "    elif track_points == \"bbox\":\n",
        "        norfair.draw_boxes(frame, detections)\n",
        "        norfair.draw_tracked_boxes(frame, tracked_objects)\n",
        "\n",
        "    if fix_paths:\n",
        "        frame = paths_drawer.draw(frame, tracked_objects, coord_transformations)\n",
        "    elif paths_drawer is not None:\n",
        "        frame = paths_drawer.draw(frame, tracked_objects)\n",
        "\n",
        "    return frame\n",
        "\n",
        "\n",
        "def center(points):\n",
        "    return [np.mean(np.array(points), axis=0)]"
      ],
      "metadata": {
        "id": "gOiWZXSMb4tE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import List, Optional, Union\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from norfair import Detection\n",
        "\n",
        "\n",
        "class YOLO:\n",
        "    def __init__(self, model_path: str, device: Optional[str] = None):\n",
        "        if device is not None and \"cuda\" in device and not torch.cuda.is_available():\n",
        "            raise Exception(\n",
        "                \"Selected device='cuda', but cuda is not available to Pytorch.\"\n",
        "            )\n",
        "        # automatically set device if its None\n",
        "        elif device is None:\n",
        "            device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "        if not os.path.exists(model_path):\n",
        "            os.system(\n",
        "                f\"wget https://github.com/WongKinYiu/yolov7/releases/download/v0.1/{os.path.basename(model_path)} -O {model_path}\"\n",
        "            )\n",
        "\n",
        "        # load model\n",
        "        try:\n",
        "            self.model = torch.hub.load(\"WongKinYiu/yolov7\", \"custom\", model_path)\n",
        "        except:\n",
        "            raise Exception(\"Failed to load model from {}\".format(model_path))\n",
        "\n",
        "    def __call__(\n",
        "        self,\n",
        "        img: Union[str, np.ndarray],\n",
        "        conf_threshold: float = 0.25,\n",
        "        iou_threshold: float = 0.45,\n",
        "        image_size: int = 720,\n",
        "        classes: Optional[List[int]] = None,\n",
        "    ) -> torch.tensor:\n",
        "\n",
        "        self.model.conf = conf_threshold\n",
        "        self.model.iou = iou_threshold\n",
        "        if classes is not None:\n",
        "            self.model.classes = classes\n",
        "        detections = self.model(img, size=image_size)\n",
        "        return detections\n",
        "\n",
        "\n",
        "def yolo_detections_to_norfair_detections(\n",
        "    yolo_detections: torch.tensor, track_points: str = \"centroid\"  # bbox or centroid\n",
        ") -> List[Detection]:\n",
        "    \"\"\"convert detections_as_xywh to norfair detections\"\"\"\n",
        "    norfair_detections: List[Detection] = []\n",
        "\n",
        "    if track_points == \"centroid\":\n",
        "        detections_as_xywh = yolo_detections.xywh[0]\n",
        "        for detection_as_xywh in detections_as_xywh:\n",
        "            centroid = np.array(\n",
        "                [\n",
        "                    [detection_as_xywh[0].item(), detection_as_xywh[1].item()],\n",
        "                    [detection_as_xywh[0].item(), detection_as_xywh[1].item()],\n",
        "                ]\n",
        "            )\n",
        "            scores = np.array(\n",
        "                [detection_as_xywh[4].item(), detection_as_xywh[4].item()]\n",
        "            )\n",
        "            norfair_detections.append(Detection(points=centroid, scores=scores))\n",
        "    elif track_points == \"bbox\":\n",
        "        detections_as_xyxy = yolo_detections.xyxy[0]\n",
        "        for detection_as_xyxy in detections_as_xyxy:\n",
        "            bbox = np.array(\n",
        "                [\n",
        "                    [detection_as_xyxy[0].item(), detection_as_xyxy[1].item()],\n",
        "                    [detection_as_xyxy[2].item(), detection_as_xyxy[3].item()],\n",
        "                ]\n",
        "            )\n",
        "            scores = np.array(\n",
        "                [detection_as_xyxy[4].item(), detection_as_xyxy[4].item()]\n",
        "            )\n",
        "            norfair_detections.append(Detection(points=bbox, scores=scores))\n",
        "\n",
        "    return norfair_detections"
      ],
      "metadata": {
        "id": "CY4fcHVcXZaE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from typing import List, Tuple, Dict, Set\n",
        "from norfair.tracker import Detection, TrackedObject\n",
        "from norfair import AbsolutePaths, Paths, Tracker, Video\n",
        "from norfair.camera_motion import HomographyTransformationGetter, MotionEstimator\n",
        "from norfair.distances import create_normalized_mean_euclidean_distance\n",
        "\n",
        "DISTANCE_THRESHOLD_CENTROID: float = 0.08"
      ],
      "metadata": {
        "id": "tKJ8yZphRadN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Alerts with timestamps"
      ],
      "metadata": {
        "id": "mUza9AF7OvQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_in_checkout_zone(points: np.ndarray, zone: Tuple[int, int, int, int]) -> bool:\n",
        "    \"\"\"Check if points are in the checkout zone\"\"\"\n",
        "    x_min, y_min, x_max, y_max = zone\n",
        "\n",
        "    box_x_min = min(points[0][0], points[1][0])\n",
        "    box_y_min = min(points[0][1], points[1][1])\n",
        "    box_x_max = max(points[0][0], points[1][0])\n",
        "    box_y_max = max(points[0][1], points[1][1])\n",
        "\n",
        "    return (box_x_min < x_max and box_x_max > x_min and\n",
        "            box_y_min < y_max and box_y_max > y_min)\n",
        "\n",
        "def check_line_crossing(current_pos: np.ndarray,\n",
        "                       previous_pos: np.ndarray,\n",
        "                       line_start: Tuple[int, int],\n",
        "                       line_end: Tuple[int, int]) -> Tuple[bool, str]:\n",
        "    \"\"\"\n",
        "    Check if a tracked object has crossed the line and determine the direction\n",
        "    Returns: (has_crossed, direction) where direction is \"entrance\" or \"exit\"\n",
        "    \"\"\"\n",
        "    if previous_pos is None:\n",
        "        return False, \"\"\n",
        "\n",
        "    current_centroid = np.mean(current_pos, axis=0)\n",
        "    previous_centroid = np.mean(previous_pos, axis=0)\n",
        "\n",
        "    def ccw(A, B, C):\n",
        "        return (C[1] - A[1]) * (B[0] - A[0]) > (B[1] - A[1]) * (C[0] - A[0])\n",
        "\n",
        "    A = current_centroid\n",
        "    B = previous_centroid\n",
        "    C = np.array(line_start)\n",
        "    D = np.array(line_end)\n",
        "\n",
        "    has_crossed = ccw(A, C, D) != ccw(B, C, D) and ccw(A, B, C) != ccw(A, B, D)\n",
        "\n",
        "    if has_crossed:\n",
        "        # Determine direction by checking if moving left to right or right to left\n",
        "        # Since the line is diagonal, we'll use x-coordinate change as the primary indicator\n",
        "        moving_right = current_centroid[0] > previous_centroid[0]\n",
        "        direction = \"entrance\" if moving_right else \"exit\"\n",
        "        return True, direction\n",
        "\n",
        "    return False, \"\"\n",
        "\n",
        "class ZoneTracker:\n",
        "    def __init__(self):\n",
        "        self.currently_in_checkout: Set[int] = set()   # IDs currently in checkout\n",
        "        self.has_visited_checkout: Set[int] = set()    # IDs that have visited checkout\n",
        "        self.alerted_entrance: Set[int] = set()        # IDs that have triggered entrance alert\n",
        "        self.alerted_exit: Set[int] = set()           # IDs that have triggered exit alert\n",
        "        self.frame_count = 0                          # Counter for frames processed\n",
        "\n",
        "    def format_timestamp(self, frame_count: int, fps: float) -> str:\n",
        "        \"\"\"Convert frame count to MM:SS.mmm format\"\"\"\n",
        "        total_seconds = frame_count / fps\n",
        "        minutes = int(total_seconds // 60)\n",
        "        seconds = int(total_seconds % 60)\n",
        "        milliseconds = int((total_seconds % 1) * 1000)\n",
        "        return f\"{minutes:02d}:{seconds:02d}.{milliseconds:03d}\"\n",
        "\n",
        "    def process_tracked_objects(self,\n",
        "                              tracked_objects: List[TrackedObject],\n",
        "                              checkout_zone: Tuple[int, int, int, int],\n",
        "                              line_points: Tuple[Tuple[int, int], Tuple[int, int]],\n",
        "                              track_points: str,\n",
        "                              fps: float = 30.0) -> List[str]:\n",
        "        \"\"\"Process tracked objects and return list of alerts\"\"\"\n",
        "        alerts = []\n",
        "        currently_in_checkout = set()\n",
        "\n",
        "        # Increment frame counter\n",
        "        self.frame_count += 1\n",
        "\n",
        "        # Get current timestamp\n",
        "        timestamp = self.format_timestamp(self.frame_count, fps)\n",
        "\n",
        "        for obj in tracked_objects:\n",
        "            current_points = obj.estimate\n",
        "            past_points = obj.past_detections[-1].points if obj.past_detections else current_points\n",
        "\n",
        "            # Check if object is in checkout zone\n",
        "            in_checkout = is_in_checkout_zone(current_points, checkout_zone)\n",
        "            if in_checkout:\n",
        "                currently_in_checkout.add(obj.id)\n",
        "\n",
        "                # Check for new entries to checkout\n",
        "                if obj.id not in self.currently_in_checkout:\n",
        "                    alerts.append(f\"[{timestamp}] ALERT: Person {obj.id} entered checkout zone\")\n",
        "                    self.has_visited_checkout.add(obj.id)\n",
        "\n",
        "            # Check for exits from checkout\n",
        "            if obj.id in self.currently_in_checkout and not in_checkout:\n",
        "                alerts.append(f\"[{timestamp}] ALERT: Person {obj.id} left checkout zone\")\n",
        "\n",
        "            # Check for line crossing\n",
        "            crossed, direction = check_line_crossing(current_points, past_points,\n",
        "                                                  line_points[0], line_points[1])\n",
        "\n",
        "            if crossed:\n",
        "                if direction == \"entrance\" and obj.id not in self.alerted_entrance:\n",
        "                    alerts.append(f\"[{timestamp}] ALERT: Person {obj.id} entered through entrance line\")\n",
        "                    self.alerted_entrance.add(obj.id)\n",
        "                elif direction == \"exit\" and obj.id not in self.alerted_exit:\n",
        "                    if obj.id in self.has_visited_checkout:\n",
        "                        alerts.append(f\"[{timestamp}] ALERT: Person {obj.id} exited after visiting checkout\")\n",
        "                    else:\n",
        "                        alerts.append(f\"[{timestamp}] ALERT: Person {obj.id} exited WITHOUT visiting checkout\")\n",
        "                    self.alerted_exit.add(obj.id)\n",
        "\n",
        "        # Update currently in checkout set\n",
        "        self.currently_in_checkout = currently_in_checkout\n",
        "\n",
        "        return alerts\n",
        "\n",
        "def inference(\n",
        "    input_video: str, model: str, track_points: str, model_threshold: str, classes: List\n",
        "):\n",
        "    coord_transformations = None\n",
        "    paths_drawer = None\n",
        "    fix_paths = True\n",
        "    model = YOLO(model)\n",
        "    video = Video(input_path=input_video)\n",
        "\n",
        "    transformations_getter = HomographyTransformationGetter()\n",
        "    motion_estimator = MotionEstimator(\n",
        "        max_points=500, min_distance=7, transformations_getter=transformations_getter\n",
        "    )\n",
        "\n",
        "    distance_function = create_normalized_mean_euclidean_distance(\n",
        "        video.input_height, video.input_width\n",
        "    )\n",
        "    distance_threshold = DISTANCE_THRESHOLD_CENTROID\n",
        "\n",
        "    tracker = Tracker(\n",
        "        distance_function=distance_function,\n",
        "        distance_threshold=distance_threshold,\n",
        "    )\n",
        "\n",
        "    paths_drawer = Paths(center, attenuation=0.01)\n",
        "\n",
        "    if fix_paths:\n",
        "        paths_drawer = AbsolutePaths(max_history=40, thickness=2)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    # Define zones\n",
        "    checkout_zone = (874, 300, 1120, 1080)  # x_min, y_min, x_max, y_max\n",
        "    entrance_exit_line = ((850, 80), (700, 204))  # (start_x, start_y), (end_x, end_y)\n",
        "\n",
        "    # Initialize zone tracker\n",
        "    zone_tracker = ZoneTracker()\n",
        "\n",
        "    # Get video FPS\n",
        "    fps = video.fps if hasattr(video, 'fps') else 25.0\n",
        "\n",
        "    for frame in video:\n",
        "        yolo_detections = model(\n",
        "            frame,\n",
        "            conf_threshold=model_threshold,\n",
        "            iou_threshold=0.45,\n",
        "            image_size=720,\n",
        "            classes=classes,\n",
        "        )\n",
        "\n",
        "        mask = np.ones(frame.shape[:2], frame.dtype)\n",
        "        coord_transformations = motion_estimator.update(frame, mask)\n",
        "        detections = yolo_detections_to_norfair_detections(\n",
        "            yolo_detections, track_points=track_points\n",
        "        )\n",
        "        tracked_objects = tracker.update(\n",
        "            detections=detections, coord_transformations=coord_transformations\n",
        "        )\n",
        "\n",
        "        # Process zones and generate alerts with FPS parameter\n",
        "        alerts = zone_tracker.process_tracked_objects(\n",
        "            tracked_objects, checkout_zone, entrance_exit_line, track_points, fps=fps\n",
        "        )\n",
        "\n",
        "        # Print all alerts\n",
        "        for alert in alerts:\n",
        "            print(alert)"
      ],
      "metadata": {
        "id": "auvj1AmkOymY"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inference(\n",
        "    \"client-vid.mp4\",\n",
        "    \"yolov7.pt\",\n",
        "    \"bbox\",\n",
        "    0.25,\n",
        "    [0],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643,
          "referenced_widgets": [
            "8de91d43c78e4dd785cf527d608f3ca3",
            "daf8d1fc31f9445dbd1866b2f3dfb8d2"
          ]
        },
        "id": "QLs7ExOkPHbe",
        "outputId": "e4ef4ac6-d7b3-49c3-ea1d-d17a963b8039"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/WongKinYiu_yolov7_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31m\u001b[1mrequirements:\u001b[0m numpy<1.24.0,>=1.18.5 not found and is required by YOLOR, attempting auto-update...\n",
            "Requirement already satisfied: numpy<1.24.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m protobuf<4.21.3 not found and is required by YOLOR, attempting auto-update...\n",
            "Requirement already satisfied: protobuf<4.21.3 in /usr/local/lib/python3.10/dist-packages (4.21.2)\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m 2 packages updated per /root/.cache/torch/hub/WongKinYiu_yolov7_main/requirements.txt\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:You are using a scalar distance function. If you want to speed up the tracking process please consider using a vectorized distance function such as ['iou', 'iou_opt', 'braycurtis', 'canberra', 'chebyshev', 'cityblock', 'correlation', 'cosine', 'dice', 'euclidean', 'hamming', 'jaccard', 'jensenshannon', 'kulczynski1', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adding autoShape... \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8de91d43c78e4dd785cf527d608f3ca3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:00.320] ALERT: Person 1 entered checkout zone\n",
            "[00:00.480] ALERT: Person 2 entered checkout zone\n",
            "[00:00.760] ALERT: Person 3 entered checkout zone\n",
            "[00:03.720] ALERT: Person 4 entered through entrance line\n",
            "[00:07.160] ALERT: Person 5 entered checkout zone\n",
            "[00:07.759] ALERT: Person 5 left checkout zone\n",
            "[00:09.320] ALERT: Person 5 entered checkout zone\n",
            "[00:09.880] ALERT: Person 5 left checkout zone\n",
            "[00:10.039] ALERT: Person 5 entered checkout zone\n",
            "[00:11.679] ALERT: Person 6 entered checkout zone\n",
            "[00:12.039] ALERT: Person 5 left checkout zone\n",
            "[00:13.160] ALERT: Person 5 entered checkout zone\n",
            "[00:13.640] ALERT: Person 5 left checkout zone\n",
            "[00:13.640] ALERT: Person 7 entered checkout zone\n",
            "[00:19.440] ALERT: Person 8 entered checkout zone\n",
            "[00:28.079] ALERT: Person 11 entered checkout zone\n",
            "[00:30.839] ALERT: Person 9 entered checkout zone\n",
            "[00:32.159] ALERT: Person 11 left checkout zone\n",
            "[00:34.880] ALERT: Person 11 entered checkout zone\n",
            "[00:35.159] ALERT: Person 11 left checkout zone\n",
            "[00:37.359] ALERT: Person 11 exited after visiting checkout\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization"
      ],
      "metadata": {
        "id": "yTxMKFEYyi2B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from typing import List, Dict\n",
        "from norfair.tracker import TrackedObject\n",
        "\n",
        "def create_visualization(\n",
        "    tracked_objects: List[TrackedObject],\n",
        "    width: int = 1920,\n",
        "    height: int = 1080,\n",
        "    trajectories: Dict[int, List[tuple]] = None,\n",
        "    checkout_zone: tuple = (874, 300, 1120, 1080),\n",
        "    entry_exit_line: tuple = ((850, 80), (700, 204))\n",
        "):\n",
        "    \"\"\"Create a visualization frame showing tracked objects and their movements\"\"\"\n",
        "    # Initialize black canvas\n",
        "    frame = np.zeros((height, width, 3), dtype=np.uint8)\n",
        "\n",
        "    # Draw checkout zone in blue (semi-transparent)\n",
        "    x_min, y_min, x_max, y_max = checkout_zone\n",
        "    cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (255, 0, 0), 2)\n",
        "    overlay = frame.copy()\n",
        "    cv2.rectangle(overlay, (x_min, y_min), (x_max, y_max), (255, 0, 0), -1)\n",
        "    cv2.addWeighted(overlay, 0.2, frame, 0.8, 0, frame)\n",
        "\n",
        "    # Draw entry/exit line in yellow\n",
        "    start_point, end_point = entry_exit_line\n",
        "    cv2.line(frame, start_point, end_point, (0, 255, 255), 2)\n",
        "\n",
        "    # Draw legend\n",
        "    cv2.putText(frame, \"Blue Box: Checkout Zone\", (50, 50),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
        "    cv2.putText(frame, \"Yellow Line: Entry/Exit Line\", (50, 100),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n",
        "    cv2.putText(frame, \"Green Dots: Current Positions\", (50, 150),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "    cv2.putText(frame, \"White Lines: Trajectories\", (50, 200),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
        "\n",
        "    # Initialize trajectories dict if None\n",
        "    if trajectories is None:\n",
        "        trajectories = {}\n",
        "\n",
        "    # Update trajectories and draw current positions\n",
        "    for obj in tracked_objects:\n",
        "        obj_id = obj.id\n",
        "        centroid = tuple(map(int, np.mean(obj.estimate, axis=0)))\n",
        "\n",
        "        # Update trajectory\n",
        "        if obj_id not in trajectories:\n",
        "            trajectories[obj_id] = []\n",
        "        trajectories[obj_id].append(centroid)\n",
        "\n",
        "        # Draw trajectory (white line)\n",
        "        if len(trajectories[obj_id]) > 1:\n",
        "            for i in range(1, len(trajectories[obj_id])):\n",
        "                cv2.line(frame,\n",
        "                        trajectories[obj_id][i-1],\n",
        "                        trajectories[obj_id][i],\n",
        "                        (255, 255, 255), 1)\n",
        "\n",
        "        # Draw current position (green dot)\n",
        "        cv2.circle(frame, centroid, 5, (0, 255, 0), -1)\n",
        "\n",
        "        # Draw ID\n",
        "        cv2.putText(frame, f\"ID: {obj_id}\",\n",
        "                    (centroid[0] + 10, centroid[1] - 10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
        "\n",
        "    return frame, trajectories\n",
        "\n",
        "def inference_with_visualization(\n",
        "    input_video: str,\n",
        "    output_video: str,\n",
        "    model: str,\n",
        "    track_points: str,\n",
        "    model_threshold: str,\n",
        "    classes: List\n",
        "):\n",
        "    # Previous initialization code remains the same\n",
        "    coord_transformations = None\n",
        "    paths_drawer = None\n",
        "    fix_paths = True\n",
        "    model = YOLO(model)\n",
        "    video = Video(input_path=input_video)\n",
        "\n",
        "    # Get video properties\n",
        "    width = int(video.input_width)\n",
        "    height = int(video.input_height)\n",
        "\n",
        "    # Create video writer for visualization\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_video, fourcc, 30.0, (width, height))\n",
        "\n",
        "    # Initialize other components\n",
        "    transformations_getter = HomographyTransformationGetter()\n",
        "    motion_estimator = MotionEstimator(\n",
        "        max_points=500, min_distance=7, transformations_getter=transformations_getter\n",
        "    )\n",
        "\n",
        "    distance_function = create_normalized_mean_euclidean_distance(height, width)\n",
        "    distance_threshold = DISTANCE_THRESHOLD_CENTROID\n",
        "\n",
        "    tracker = Tracker(\n",
        "        distance_function=distance_function,\n",
        "        distance_threshold=distance_threshold,\n",
        "    )\n",
        "\n",
        "    # Define zones\n",
        "    checkout_zone = (874, 300, 1120, 1080)\n",
        "    entrance_exit_line = ((850, 80), (700, 204))\n",
        "\n",
        "    # Initialize zone tracker and trajectories\n",
        "    zone_tracker = ZoneTracker()\n",
        "    trajectories = {}\n",
        "\n",
        "    for frame in video:\n",
        "        yolo_detections = model(\n",
        "            frame,\n",
        "            conf_threshold=model_threshold,\n",
        "            iou_threshold=0.45,\n",
        "            image_size=720,\n",
        "            classes=classes,\n",
        "        )\n",
        "\n",
        "        mask = np.ones(frame.shape[:2], frame.dtype)\n",
        "        coord_transformations = motion_estimator.update(frame, mask)\n",
        "        detections = yolo_detections_to_norfair_detections(\n",
        "            yolo_detections, track_points=track_points\n",
        "        )\n",
        "        tracked_objects = tracker.update(\n",
        "            detections=detections, coord_transformations=coord_transformations\n",
        "        )\n",
        "\n",
        "        # Process zones and generate alerts\n",
        "        alerts = zone_tracker.process_tracked_objects(\n",
        "            tracked_objects, checkout_zone, entrance_exit_line, track_points\n",
        "        )\n",
        "\n",
        "        # Print alerts\n",
        "        for alert in alerts:\n",
        "            print(alert)\n",
        "\n",
        "        # Create visualization frame\n",
        "        viz_frame, trajectories = create_visualization(\n",
        "            tracked_objects,\n",
        "            width,\n",
        "            height,\n",
        "            trajectories,\n",
        "            checkout_zone,\n",
        "            entrance_exit_line\n",
        "        )\n",
        "\n",
        "        # Write visualization frame\n",
        "        out.write(viz_frame)\n",
        "\n",
        "    # Release video writer\n",
        "    out.release()\n",
        "\n",
        "    return \"Visualization completed and saved to \" + output_video"
      ],
      "metadata": {
        "id": "qUYJ5QSMyYg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inference_with_visualization(\n",
        "    input_video=\"client-vid.mp4\",\n",
        "    output_video=\"visualization.mp4\",\n",
        "    model=\"yolov7.pt\",\n",
        "    track_points=\"bbox\",\n",
        "    model_threshold=0.25,\n",
        "    classes=[0]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661,
          "referenced_widgets": [
            "c0a6ba42d6f3410d85a16fff155cd6a6",
            "a461810ab16242e8be3273ef4fc5ce88"
          ]
        },
        "id": "aiq51mOmyYxw",
        "outputId": "c79dc6f6-050f-4f26-84cf-74d976ad0277"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/WongKinYiu_yolov7_main\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31m\u001b[1mrequirements:\u001b[0m numpy<1.24.0,>=1.18.5 not found and is required by YOLOR, attempting auto-update...\n",
            "Requirement already satisfied: numpy<1.24.0,>=1.18.5 in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m protobuf<4.21.3 not found and is required by YOLOR, attempting auto-update...\n",
            "Requirement already satisfied: protobuf<4.21.3 in /usr/local/lib/python3.10/dist-packages (4.21.2)\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m 2 packages updated per /root/.cache/torch/hub/WongKinYiu_yolov7_main/requirements.txt\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m ⚠️ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:You are using a scalar distance function. If you want to speed up the tracking process please consider using a vectorized distance function such as ['iou', 'iou_opt', 'braycurtis', 'canberra', 'chebyshev', 'cityblock', 'correlation', 'cosine', 'dice', 'euclidean', 'hamming', 'jaccard', 'jensenshannon', 'kulczynski1', 'mahalanobis', 'matching', 'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', 'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adding autoShape... \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Output()"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c0a6ba42d6f3410d85a16fff155cd6a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ALERT: Person 1 entered checkout zone\n",
            "ALERT: Person 2 entered checkout zone\n",
            "ALERT: Person 3 entered checkout zone\n",
            "ALERT: Person 4 entered through entrance line\n",
            "ALERT: Person 5 entered checkout zone\n",
            "ALERT: Person 5 left checkout zone\n",
            "ALERT: Person 5 entered checkout zone\n",
            "ALERT: Person 5 left checkout zone\n",
            "ALERT: Person 5 entered checkout zone\n",
            "ALERT: Person 6 entered checkout zone\n",
            "ALERT: Person 5 left checkout zone\n",
            "ALERT: Person 5 entered checkout zone\n",
            "ALERT: Person 5 left checkout zone\n",
            "ALERT: Person 7 entered checkout zone\n",
            "ALERT: Person 8 entered checkout zone\n",
            "ALERT: Person 11 entered checkout zone\n",
            "ALERT: Person 9 entered checkout zone\n",
            "ALERT: Person 11 left checkout zone\n",
            "ALERT: Person 11 entered checkout zone\n",
            "ALERT: Person 11 left checkout zone\n",
            "ALERT: Person 11 exited after visiting checkout\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Visualization completed and saved to visualization.mp4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XoWWccUDyeJU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "d1d45f7b56f6e27d41b86676aa8ae2293c110fadaa7f6b0b931d437bdf9db7e9"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c0a6ba42d6f3410d85a16fff155cd6a6": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_a461810ab16242e8be3273ef4fc5ce88",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "client-vid.mp4 \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m8.12fps\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">client-vid.mp4 <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> <span style=\"color: #808000; text-decoration-color: #808000\">8.12fps</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "a461810ab16242e8be3273ef4fc5ce88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8de91d43c78e4dd785cf527d608f3ca3": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_daf8d1fc31f9445dbd1866b2f3dfb8d2",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "client-vid.mp4 \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[35m100%\u001b[0m \u001b[36m0:00:00\u001b[0m \u001b[33m9.63fps\u001b[0m\n",
                  "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">client-vid.mp4 <span style=\"color: #729c1f; text-decoration-color: #729c1f\">━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━</span> <span style=\"color: #800080; text-decoration-color: #800080\">100%</span> <span style=\"color: #008080; text-decoration-color: #008080\">0:00:00</span> <span style=\"color: #808000; text-decoration-color: #808000\">9.63fps</span>\n</pre>\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "daf8d1fc31f9445dbd1866b2f3dfb8d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}